---
layout: post
date: 2023-01-01
published: true
sitemap: false
title: "Sounds versus phonemes"
description: "Tezcan et al. (2023)<br><i>eLife</i>"
categories: TRF, comprehended, uncomprehended, speech
media: Journal
turl: https://pure.mpg.de/pubman/faces/ViewItemFullPage.jsp?itemId=item_3518643_2
time_period: 2023
thumbnail: "/posts/2023_filiz_elife/2023_filiz_elife.webp"

website:
  button_text: Visit the site
  url: https://www.butterfly.life/

intro: |
  When we comprehend language from speech, the phase of the neural response aligns with particular features of the speech input, resulting in a phenomenon referred to as neural tracking. In recent years, a large body of work has demonstrated the tracking of the acoustic envelope and abstract linguistic units at the phoneme and word levels, and beyond. However, the degree to which speech tracking is driven by acoustic edges of the signal, or by internally-generated linguistic units, or by the interplay of both, remains contentious. In this study, we used naturalistic story-listening to investigate (1) whether phoneme-level features are tracked over and above acoustic edges, (2) whether word entropy, which can reflect sentence- and discourse-level constraints, impacted the encoding of acoustic and phoneme- level features, and (3) whether the tracking of acoustic edges was enhanced or suppressed during comprehension of a first language (Dutch) compared to a statistically familiar but uncomprehended language  (French). We first show that encoding models with phoneme-level linguistic features, in addition to acoustic features, uncovered an increased neural tracking response; this signal was further amplified in a comprehended language, putatively reflecting the transformation of acoustic features into internally generated phoneme-level representations. Phonemes were tracked more  strongly in a comprehended language, suggesting that language comprehension functions as a neural filter over acoustic edges of the speech signal as it transforms sensory signals into abstract  linguistic units. We then show that word entropy enhances neural tracking of both acoustic and phonemic features when sentence- and discourse-context are less constraining. When language was not comprehended, acoustic features, but not phonemic ones, were more strongly modulated, but in contrast, when a native language is comprehended, phoneme features are more strongly modulated. Taken together, our findings highlight the flexible modulation of acoustic, and phonemic features by sentence and discourse- level constraint in language comprehension, and document the neural transformation from speech perception to language comprehension, consistent with an account of language processing as a neural filter from sensory to abstract representations.

content_layout:
  - section_layout: 1col
    images:
      - caption: Main functional tabs
        description: 'Idea placeholder'
        url: '/posts/butterfly/butterfly-main-navigation.jpg'
        width:
        height:

  - section_layout: 1col
    images:
      - caption: Public profile media
        description: 'Profile screens'
        url: '/posts/butterfly/butterfly-profile.jpg'
        width:
        height:

  - section_layout: 1col
    images:
      - caption: Onboarding
        description: 'Results placeholder'
        url: '/posts/butterfly/butterfly-onboarding.jpg'
        width:
        height:

  - section_layout: 1col
    images:
      - caption: Chat
        description: 'Conclusion placeholder'
        url: '/posts/butterfly/butterfly-chat.jpg'
        width:
        height:
---

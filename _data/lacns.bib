
@ARTICLE{Kemmerer2022-bi,
  title    = "{Parietal but not temporoparietal alpha-tACS modulates endogenous
              visuospatial attention}",
  author   = "Kemmerer, Selma K and de Graaf, Tom A and Ten Oever, Sanne and
              Erkens, Mayke and De Weerd, Peter and Sack, Alexander T",
  abstract = "Visuospatial attention can either be voluntarily directed
              (endogenous/top-down attention) or automatically triggered
              (exogenous/bottom-up attention). Recent research showed that
              dorsal parietal transcranial alternating current stimulation
              (tACS) at alpha frequency modulates the spatial attentional bias
              in an endogenous but not in an exogenous visuospatial attention
              task. Yet, the reason for this task-specificity remains
              unexplored. Here, we tested whether this dissociation relates to
              the proposed differential role of the dorsal attention network
              (DAN) and ventral attention network (VAN) in endogenous and
              exogenous attention processes respectively. To that aim, we
              targeted the left and right dorsal parietal node of the DAN, as
              well as the left and right ventral temporoparietal node of the
              VAN using tACS at the individual alpha frequency. Every
              participant completed all four stimulation conditions and a sham
              condition in five separate sessions. During tACS, we assessed the
              behavioral visuospatial attention bias via an endogenous and
              exogenous visuospatial attention task. Additionally, we measured
              offline alpha power immediately before and after tACS using
              electroencephalography (EEG). The behavioral data revealed an
              effect of tACS on the endogenous but not exogenous attention
              bias, with a greater leftward bias during (sham-corrected) left
              than right hemispheric stimulation. In line with our hypothesis,
              this effect was brain area-specific, i.e., present for dorsal
              parietal but not ventral temporoparietal tACS. However, contrary
              to our expectations, there was no effect of ventral
              temporoparietal tACS on the exogenous visuospatial attention
              bias. Hence, no double dissociation between the two targeted
              attention networks. There was no effect of either tACS condition
              on offline alpha power. Our behavioral data reveal that dorsal
              parietal but not ventral temporoparietal alpha oscillations steer
              endogenous visuospatial attention. This brain-area specific tACS
              effect matches the previously proposed dissociation between the
              DAN and VAN and, by showing that the spatial attention bias
              effect does not generalize to any lateral posterior tACS montage,
              renders lateral cutaneous and retinal effects for the spatial
              attention bias in the dorsal parietal condition unlikely. Yet the
              absence of tACS effects on the exogenous attention task suggests
              that ventral temporoparietal alpha oscillations are not
              functionally relevant for exogenous visuospatial attention. We
              discuss the potential implications of this finding in the context
              of an emerging theory on the role of the ventral temporoparietal
              node.",
  journal  = "Cortex",
  volume   =  154,
  pages    = "149--166",
  month    =  sep,
  year     =  2022,
  keywords = "Alpha oscillations; Dorsal attention network (DAN); Transcranial
              alternating current stimulation (tACS); Ventral attention network
              (VAN); Visuospatial attention",
  language = "en",
  issn     = "0010-9452, 1973-8102",
  pmid     = "35779382",
  doi      = "10.1016/j.cortex.2022.01.021"
}

@ARTICLE{Ten_Oever2022-mu,
  title    = "{Neural tracking of phrases in spoken language comprehension is
              automatic and task-dependent}",
  author   = "Ten Oever, Sanne and Carta, Sara and Kaufeld, Greta and Martin,
              Andrea E",
  abstract = "Linguistic phrases are tracked in sentences even though there is
              no one-to-one acoustic phrase marker in the physical signal. This
              phenomenon suggests an automatic tracking of abstract linguistic
              structure that is endogenously generated by the brain. However,
              all studies investigating linguistic tracking compare conditions
              where either relevant information at linguistic timescales is
              available, or where this information is absent altogether (e.g.,
              sentences versus word lists during passive listening). It is
              therefore unclear whether tracking at phrasal timescales is
              related to the content of language, or rather, results as a
              consequence of attending to the timescales that happen to match
              behaviourally relevant information. To investigate this question,
              we presented participants with sentences and word lists while
              recording their brain activity with magnetoencephalography (MEG).
              Participants performed passive, syllable, word, and
              word-combination tasks corresponding to attending to four
              different rates: one they would naturally attend to,
              syllable-rates, word-rates, and phrasal-rates, respectively. We
              replicated overall findings of stronger phrasal-rate tracking
              measured with mutual information for sentences compared to word
              lists across the classical language network. However, in the
              inferior frontal gyrus (IFG) we found a task effect suggesting
              stronger phrasal-rate tracking during the word-combination task
              independent of the presence of linguistic structure, as well as
              stronger delta-band connectivity during this task. These results
              suggest that extracting linguistic information at phrasal rates
              occurs automatically with or without the presence of an
              additional task, but also that IFG might be important for
              temporal integration across various perceptual domains.",
  journal  = "Elife",
  volume   =  11,
  pages    = "77468",
  month    =  jul,
  year     =  2022,
  file     = "All Papers/T/Ten Oever et al. 2022 -elife - Neural tracking of phrases in spoken language comprehension is automatic and task-dependent.pdf",
  keywords = "MEG; human; mutual information; neuroscience; sentence
              comprehension; speech; temporal dynamics",
  language = "en",
  issn     = "2050-084X",
  pmid     = "35833919",
  doi      = "10.7554/eLife.77468",
  pmc      = "PMC9282854"
}

@ARTICLE{Bai2022-fe,
  title    = "{Neural dynamics differentially encode phrases and sentences
              during spoken language comprehension}",
  author   = "Bai, Fan and Meyer, Antje S and Martin, Andrea E",
  abstract = "Human language stands out in the natural world as a biological
              signal that uses a structured system to combine the meanings of
              small linguistic units (e.g., words) into larger constituents
              (e.g., phrases and sentences). However, the physical dynamics of
              speech (or sign) do not stand in a one-to-one relationship with
              the meanings listeners perceive. Instead, listeners infer meaning
              based on their knowledge of the language. The neural readouts of
              the perceptual and cognitive processes underlying these
              inferences are still poorly understood. In the present study, we
              used scalp electroencephalography (EEG) to compare the neural
              response to phrases (e.g., the red vase) and sentences (e.g., the
              vase is red), which were close in semantic meaning and had been
              synthesized to be physically indistinguishable. Differences in
              structure were well captured in the reorganization of neural
              phase responses in delta (approximately <2 Hz) and theta bands
              (approximately 2 to 7 Hz),and in power and power connectivity
              changes in the alpha band (approximately 7.5 to 13.5 Hz).
              Consistent with predictions from a computational model, sentences
              showed more power, more power connectivity, and more phase
              synchronization than phrases did. Theta-gamma phase-amplitude
              coupling occurred, but did not differ between the syntactic
              structures. Spectral-temporal response function (STRF) modeling
              revealed different encoding states for phrases and sentences,
              over and above the acoustically driven neural response. Our
              findings provide a comprehensive description of how the brain
              encodes and separates linguistic structures in the dynamics of
              neural responses. They imply that phase synchronization and
              strength of connectivity are readouts for the constituent
              structure of language. The results provide a novel basis for
              future neurophysiological research on linguistic structure
              representation in the brain, and, together with our simulations,
              support time-based binding as a mechanism of structure encoding
              in neural dynamics.",
  journal  = "PLoS Biol.",
  volume   =  20,
  number   =  7,
  pages    = "e3001713",
  month    =  jul,
  year     =  2022,
  file     = "All Papers/B/Bai et al. 2022 -plos biol - Neural dynamics differentially encode phrases and sentences during spoken language comprehension.pdf",
  language = "en",
  issn     = "1544-9173, 1545-7885",
  pmid     = "35834569",
  doi      = "10.1371/journal.pbio.3001713",
  pmc      = "PMC9282610"
}

@ARTICLE{Ten_Oever2022-rs,
  title    = "{Inferring the nature of linguistic computations in the brain}",
  author   = "Ten Oever, Sanne and Kaushik, Karthikeya and Martin, Andrea E",
  abstract = "Sentences contain structure that determines their meaning beyond
              that of individual words. An influential study by Ding and
              colleagues (2016) used frequency tagging of phrases and sentences
              to show that the human brain is sensitive to structure by finding
              peaks of neural power at the rate at which structures were
              presented. Since then, there has been a rich debate on how to
              best explain this pattern of results with profound impact on the
              language sciences. Models that use hierarchical structure
              building, as well as models based on associative sequence
              processing, can predict the neural response, creating an
              inferential impasse as to which class of models explains the
              nature of the linguistic computations reflected in the neural
              readout. In the current manuscript, we discuss pitfalls and
              common fallacies seen in the conclusions drawn in the literature
              illustrated by various simulations. We conclude that inferring
              the neural operations of sentence processing based on these
              neural data, and any like it, alone, is insufficient. We discuss
              how to best evaluate models and how to approach the modeling of
              neural readouts to sentence processing in a manner that remains
              faithful to cognitive, neural, and linguistic principles.",
  journal  = "PLoS Comput. Biol.",
  volume   =  18,
  number   =  7,
  pages    = "e1010269",
  month    =  jul,
  year     =  2022,
  file     = "All Papers/T/Ten Oever et al. 2022 -plos comput biol - Inferring the nature of linguistic computations in the brain.pdf",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "35900974",
  doi      = "10.1371/journal.pcbi.1010269",
  pmc      = "PMC9333253"
}

@ARTICLE{Coopmans2022-ha,
  title     = "{Effects of structure and meaning on cortical tracking of
               linguistic units in naturalistic speech}",
  author    = "Coopmans, Cas W and de Hoop, Helen and Hagoort, Peter and
               Martin, Andrea E",
  abstract  = "Abstract Recent research has established that cortical activity
               ``tracks'' the presentation rate of syntactic phrases in
               continuous speech, even though phrases are abstract units that
               do not have direct correlates in the acoustic signal. We
               investigated whether cortical tracking of phrase structures is
               modulated by the extent to which these structures
               compositionally determine meaning. To this end, we recorded
               electroencephalography (EEG) of 38 native speakers who listened
               to naturally spoken Dutch stimuli in different conditions, which
               parametrically modulated the degree to which syntactic structure
               and lexical semantics determine sentence meaning. Tracking was
               quantified through mutual information between the EEG data and
               either the speech envelopes or abstract annotations of syntax,
               all of which were filtered in the frequency band corresponding
               to the presentation rate of phrases (1.1--2.1 Hz). Overall,
               these mutual information analyses showed stronger tracking of
               phrases in regular sentences than in stimuli whose
               lexical-syntactic content is reduced, but no consistent
               differences in tracking between sentences and stimuli that
               contain a combination of syntactic structure and lexical
               content. While there were no effects of compositional meaning on
               the degree of phrase-structure tracking, analyses of
               event-related potentials elicited by sentence-final words did
               reveal meaning-induced differences between conditions. Our
               findings suggest that cortical tracking of structure in
               sentences indexes the internal generation of this structure, a
               process that is modulated by the properties of its input, but
               not by the compositional interpretation of its output.",
  journal   = "Neurobiology of Language",
  publisher = "MIT Press - Journals",
  volume    =  3,
  number    =  3,
  pages     = "386--412",
  month     =  jun,
  year      =  2022,
  file      = "All Papers/C/Coopmans et al. 2022 -neurobiology of language - Effects of structure and meaning on cortical tracking of linguistic units in naturalistic speech.pdf",
  copyright = "https://creativecommons.org/licenses/by/4.0/",
  language  = "en",
  issn      = "2641-4368",
  doi       = "10.1162/nol\_a\_00070"
}

@ARTICLE{Janssens2022-hm,
  title    = "{Calibrating rhythmic stimulation parameters to individual
              electroencephalography markers: The consistency of individual
              alpha frequency in practical lab settings}",
  author   = "Janssens, Shanice E W and Sack, Alexander T and Ten Oever, Sanne
              and de Graaf, Tom A",
  abstract = "Rhythmic stimulation can be applied to modulate neuronal
              oscillations. Such 'entrainment' is optimized when stimulation
              frequency is individually calibrated based on
              magneto/encephalography markers. It remains unknown how
              consistent such individual markers are across days/sessions,
              within a session, or across cognitive states, hemispheres and
              estimation methods, especially in a realistic, practical, lab
              setting. We here estimated individual alpha frequency (IAF)
              repeatedly from short electroencephalography (EEG) measurements
              at rest or during an attention task (cognitive state), using
              single parieto-occipital electrodes in 24 participants on 4 days
              (between-sessions), with multiple measurements over an hour on 1
              day (within-session). First, we introduce an algorithm to
              automatically reject power spectra without a sufficiently clear
              peak to ensure unbiased IAF estimations. Then we estimated IAF
              via the traditional 'maximum' method and a 'Gaussian fit' method.
              IAF was reliable within- and between-sessions for both cognitive
              states and hemispheres, though task-IAF estimates tended to be
              more variable. Overall, the 'Gaussian fit' method was more
              reliable than the 'maximum' method. Furthermore, we evaluated how
              far from an approximated 'true' task-related IAF the selected
              'stimulation frequency' was, when calibrating this frequency
              based on a short rest-EEG, a short task-EEG, or simply selecting
              10 Hz for all participants. For the 'maximum' method, rest-EEG
              calibration was best, followed by task-EEG, and then 10 Hz. For
              the 'Gaussian fit' method, rest-EEG and task-EEG-based
              calibration were similarly accurate, and better than 10 Hz. These
              results lead to concrete recommendations about valid, and
              automated, estimation of individual oscillation markers in
              experimental and clinical settings.",
  journal  = "Eur. J. Neurosci.",
  volume   =  55,
  number   = "11-12",
  pages    = "3418--3437",
  month    =  jun,
  year     =  2022,
  file     = "All Papers/J/Janssens et al. 2022 -eur j neurosci - Calibrating rhythmic stimulation ... e consistency of individual alpha frequency in practical lab settings.pdf",
  keywords = "consistency; electroencephalography (EEG); individual alpha
              frequency (IAF); intra-class correlation coefficient (ICC);
              neuronal oscillations; reliability",
  language = "en",
  issn     = "0953-816X, 1460-9568",
  pmid     = "34363269",
  doi      = "10.1111/ejn.15418",
  pmc      = "PMC9541964"
}

@ARTICLE{Janssens2022-gg,
  title    = "{"Broadband Alpha Transcranial Alternating Current Stimulation":
              Exploring a new biologically calibrated brain stimulation
              protocol}",
  author   = "Janssens, Shanice E W and Oever, Sanne Ten and Sack, Alexander T
              and de Graaf, Tom A",
  abstract = "Transcranial alternating current stimulation (tACS) can be used
              to study causal contributions of oscillatory brain mechanisms to
              cognition and behavior. For instance, individual alpha frequency
              (IAF) tACS was reported to enhance alpha power and impact
              visuospatial attention performance. Unfortunately, such results
              have been inconsistent and difficult to replicate. In tACS,
              stimulation generally involves one frequency, sometimes
              individually calibrated to a peak value observed in an M/EEG
              power spectrum. Yet, the 'peak' actually observed in such power
              spectra often contains a broader range of frequencies, raising
              the question whether a biologically calibrated tACS protocol
              containing this fuller range of alpha-band frequencies might be
              more effective. Here, we introduce 'Broadband-alpha-tACS', a
              complex individually calibrated electrical stimulation protocol.
              We band-pass filtered left posterior resting-state EEG data
              around the IAF ($\pm$ 2 Hz), and converted that time series into
              an electrical waveform for tACS stimulation of that same left
              posterior parietal cortex location. In other words, we stimulated
              a brain region with a 'replay' of its own alpha-band frequency
              content, based on spontaneous activity. Within-subjects (N = 24),
              we compared to a sham tACS session the effects of broadband-alpha
              tACS, power-matched spectral inverse ('alpha-removed') control
              tACS, and individual alpha frequency (IAF) tACS, on EEG alpha
              power and performance in an endogenous attention task previously
              reported to be affected by alpha tACS. Broadband-alpha-tACS
              significantly modulated attention task performance (i.e., reduced
              the rightward visuospatial attention bias in trials without
              distractors, and reduced attention benefits). Alpha-removed tACS
              also reduced the rightward visuospatial attention bias. IAF-tACS
              did not significantly modulate attention task performance
              compared to sham tACS, but also did not statistically
              significantly differ from broadband-alpha-tACS. This new
              broadband-alpha-tACS approach seems promising, but should be
              further explored and validated in future studies.",
  journal  = "Neuroimage",
  volume   =  253,
  pages    = "119109",
  month    =  jun,
  year     =  2022,
  keywords = "Electroencephalography (EEG); Individual alpha frequency (IAF);
              Neuronal alpha oscillations; Transcranial alternating current
              stimulation (tACS); Visuospatial attention",
  language = "en",
  issn     = "1053-8119, 1095-9572",
  pmid     = "35306159",
  doi      = "10.1016/j.neuroimage.2022.119109"
}

@ARTICLE{Van_der_Werf2022-fu,
  title    = "{No evidence of rhythmic visuospatial attention at cued locations
              in a spatial cuing paradigm, regardless of their behavioural
              relevance}",
  author   = "van der Werf, Olof J and Ten Oever, Sanne and Schuhmann, Teresa
              and Sack, Alexander T",
  abstract = "Recent evidence suggests that visuospatial attentional
              performance is not stable over time but fluctuates in a rhythmic
              fashion. These attentional rhythms allow for sampling of
              different visuospatial locations in each cycle of this rhythm.
              However, it is still unclear in which paradigmatic circumstances
              rhythmic attention becomes evident. First, it is unclear at what
              spatial locations rhythmic attention occurs. Second, it is
              unclear how the behavioural relevance of each spatial location
              determines the rhythmic sampling patterns. Here, we aim to
              elucidate these two issues. Firstly, we aim to find evidence of
              rhythmic attention at the predicted (i.e. cued) location under
              moderately informative predictor value, replicating earlier
              studies. Secondly, we hypothesise that rhythmic attentional
              sampling behaviour will be affected by the behavioural relevance
              of the sampled location, ranging from non-informative to fully
              informative. To these aims, we used a modified Egly-Driver task
              with three conditions: a fully informative cue, a moderately
              informative cue (replication condition), and a non-informative
              cue. We did not find evidence of rhythmic sampling at cued
              locations, failing to replicate earlier studies. Nor did we find
              differences in rhythmic sampling under different predictive
              values of the cue. The current data does not allow for robust
              conclusions regarding the non-cued locations due to the absence
              of a priori hypotheses. Post-hoc explorative data analyses,
              however, clearly indicate that attention samples non-cued
              locations in a theta-rhythmic manner, specifically when the cued
              location bears higher behavioural relevance than the non-cued
              locations.",
  journal  = "Eur. J. Neurosci.",
  volume   =  55,
  number   = "11-12",
  pages    = "3100--3116",
  month    =  jun,
  year     =  2022,
  file     = "All Papers/V/van der Werf et al. 2022 -eur j neurosci - No evidence of rhythmic visuo ... n a spatial cuing paradigm, regardless of their behavioural relevance.pdf",
  keywords = "Egly-Driver task; replication; rhythmic attention; theta;
              visuospatial attention",
  language = "en",
  issn     = "0953-816X, 1460-9568",
  pmid     = "34131983",
  doi      = "10.1111/ejn.15353",
  pmc      = "PMC9542203"
}

@ARTICLE{Kemmerer2022-dl,
  title    = "{Frequency-specific transcranial neuromodulation of alpha power
              alters visuospatial attention performance}",
  author   = "Kemmerer, S K and Sack, A T and de Graaf, T A and Ten Oever, S
              and De Weerd, P and Schuhmann, T",
  abstract = "Transcranial alternating current stimulation (tACS) at 10 Hz has
              been shown to modulate spatial attention. However, the
              frequency-specificity and the oscillatory changes underlying this
              tACS effect are still largely unclear. Here, we applied
              high-definition tACS at individual alpha frequency (IAF), two
              control frequencies (IAF+/-2Hz) and sham to the left posterior
              parietal cortex and measured its effects on visuospatial
              attention performance and offline alpha power (using
              electroencephalography, EEG). We revealed a behavioural and
              electrophysiological stimulation effect relative to sham for IAF
              but not control frequency stimulation conditions: there was a
              leftward lateralization of alpha power for IAF tACS, which
              differed from sham for the first out of three minutes following
              tACS. At a high value of this EEG effect (moderation effect), we
              observed a leftward attention bias relative to sham. This effect
              was task-specific, i.e., it could be found in an endogenous
              attention but not in a detection task. Only in the IAF tACS
              condition, we also found a correlation between the magnitude of
              the alpha lateralization and the attentional bias effect. Our
              results support a functional role of alpha oscillations in
              visuospatial attention and the potential of tACS to modulate it.
              The frequency-specificity of the effects suggests that an
              individualization of the stimulation frequency is necessary in
              heterogeneous target groups with a large variation in IAF.",
  journal  = "Brain Res.",
  volume   =  1782,
  number   =  147834,
  pages    = "147834",
  month    =  may,
  year     =  2022,
  keywords = "Non-invasive brain stimulation; Oscillations; Parietal cortex;
              Transcranial alternating current stimulation (tACS); individual
              alpha frequency (IAF)",
  language = "en",
  issn     = "0006-8993, 1872-6240",
  pmid     = "35176250",
  doi      = "10.1016/j.brainres.2022.147834"
}

@ARTICLE{Coopmans2022-gg,
  title     = "{Hierarchy in language interpretation: evidence from behavioural
               experiments and computational modelling}",
  author    = "Coopmans, Cas W and de Hoop, Helen and Kaushik, Karthikeya and
               Hagoort, Peter and Martin, Andrea E",
  abstract  = "ABSTRACTIt has long been recognised that phrases and sentences
               are organised hierarchically, but many computational models of
               language treat them as sequences of words without computing
               constituent structure. Against this background, we conducted two
               experiments which showed that participants interpret ambiguous
               noun phrases, such as second blue ball, in terms of their
               abstract hierarchical structure rather than their linear surface
               order. When a neural network model was tested on this task, it
               could simulate such ?hierarchical? behaviour. However, when we
               changed the training data such that they were not entirely
               unambiguous anymore, the model stopped generalising in a
               human-like way. It did not systematically generalise to novel
               items, and when it was trained on ambiguous trials, it strongly
               favoured the linear interpretation. We argue that these models
               should be endowed with a bias to make generalisations over
               hierarchical structure in order to be cognitively adequate
               models of human language.",
  journal   = "Language, Cognition and Neuroscience",
  publisher = "Routledge",
  volume    =  37,
  number    =  4,
  pages     = "420--439",
  month     =  apr,
  year      =  2022,
  file      = "All Papers/C/Coopmans et al. 2022 -language, cognition and neuroscience - Hierarchy i ... n - evidence from behavioural experiments and computational modelling.pdf",
  copyright = "http://creativecommons.org/licenses/by/4.0/",
  language  = "en",
  issn      = "2327-3798, 2327-3801",
  doi       = "10.1080/23273798.2021.1980595"
}

@ARTICLE{Doumas2022-vx,
  title     = "{A theory of relation learning and cross-domain generalization}",
  author    = "Doumas, Leonidas A A and Puebla, Guillermo and Martin, Andrea E
               and Hummel, John E",
  abstract  = "People readily generalize knowledge to novel domains and
               stimuli. We present a theory, instantiated in a computational
               model, based on the idea that cross-domain generalization in
               humans is a case of analogical inference over structured (i.e.,
               symbolic) relational representations. The model is an extension
               of the Learning and Inference with Schemas and Analogy (LISA;
               Hummel \& Holyoak, 1997, 2003) and Discovery of Relations by
               Analogy (DORA; Doumas et al., 2008) models of relational
               inference and learning. The resulting model learns both the
               content and format (i.e., structure) of relational
               representations from nonrelational inputs without supervision,
               when augmented with the capacity for reinforcement learning it
               leverages these representations to learn about individual
               domains, and then generalizes to new domains on the first
               exposure (i.e., zero-shot learning) via analogical inference. We
               demonstrate the capacity of the model to learn structured
               relational representations from a variety of simple visual
               stimuli, and to perform cross-domain generalization between
               video games (Breakout and Pong) and between several
               psychological tasks. We demonstrate that the model's trajectory
               closely mirrors the trajectory of children as they learn about
               relations, accounting for phenomena from the literature on the
               development of children's reasoning and analogy making. The
               model's ability to generalize between domains demonstrates the
               flexibility afforded by representing domains in terms of their
               underlying relational structure, rather than simply in terms of
               the statistical relations between their inputs and outputs.
               (PsycInfo Database Record (c) 2022 APA, all rights reserved).",
  journal   = "Psychol. Rev.",
  publisher = "online publication",
  month     =  feb,
  year      =  2022,
  file      = "All Papers/D/Doumas et al. 2022 -psychol rev - A theory of relation learning and cross-domain generalization.pdf",
  language  = "en",
  issn      = "0033-295X, 1939-1471",
  pmid      = "35113620",
  doi       = "10.1037/rev0000346"
}

@INPROCEEDINGS{Dingemanse2022-bo,
  title       = "{Convergent cultural evolution of continuers (mhmm)}",
  booktitle   = "{Joint Conference on Language Evolution (JCoLE)}",
  author      = "Dingemanse, Mark and Liesenfeld, Andreas and Woensdregt,
                 Marieke",
  pages       = "160--167",
  series      = "Wacewicz (Eds.), The Evolution of Language: Proceedings of the
                 Joint Conference on Language Evolution (JCoLE)",
  institution = "Joint Conference on Language Evolution (JCoLE)",
  year        =  2022,
  address     = "Nijmegen"
}

@INPROCEEDINGS{Woensdregt2022-st,
  title       = "{Language universals rely on social cognition: Computational
                 models of the use of this and that to redirect the receiver's
                 attention}",
  booktitle   = "{the 44th Annual Meeting of the Cognitive Science Society
                 (CogSci 2022)}",
  author      = "Woensdregt, Marieke and Jara-Ettinger, Julian and
                 Rubio-Fernandez, Paula",
  publisher   = "Cognitive Science Society",
  volume      =  2022,
  pages       = "1382--1388",
  series      = "Ramenzoni (Eds.), Proceedings of the 44th Annual Conference of
                 the Cognitive Science Society (CogSci",
  institution = "Cognitive Science Society",
  year        =  2022,
  address     = "Toronto, Canada"
}

@ARTICLE{Petras2021-lm,
  title    = "{Information redundancy across spatial scales modulates early
              visual cortical processing}",
  author   = "Petras, Kirsten and Ten Oever, Sanne and Dalal, Sarang S and
              Goffaux, Valerie",
  abstract = "Visual images contain redundant information across spatial scales
              where low spatial frequency contrast is informative towards the
              location and likely content of high spatial frequency detail.
              Previous research suggests that the visual system makes use of
              those redundancies to facilitate efficient processing. In this
              framework, a fast, initial analysis of low-spatial frequency
              (LSF) information guides the slower and later processing of high
              spatial frequency (HSF) detail. Here, we used multivariate
              classification as well as time-frequency analysis of MEG
              responses to the viewing of intact and phase scrambled images of
              human faces to demonstrate that the availability of redundant LSF
              information, as found in broadband intact images, correlates with
              a reduction in HSF representational dominance in both early and
              higher-level visual areas as well as a reduction of gamma-band
              power in early visual cortex. Our results indicate that the cross
              spatial frequency information redundancy that can be found in all
              natural images might be a driving factor in the efficient
              integration of fine image details.",
  journal  = "Neuroimage",
  volume   =  244,
  pages    = "118613",
  month    =  dec,
  year     =  2021,
  language = "en",
  issn     = "1053-8119, 1095-9572",
  pmid     = "34563683",
  doi      = "10.1016/j.neuroimage.2021.118613",
  pmc      = "PMC8591375"
}

@ARTICLE{Ten_Oever2021-py,
  title    = "{An engram of intentionally forgotten information}",
  author   = "Ten Oever, Sanne and Sack, Alexander T and Oehrn, Carina R and
              Axmacher, Nikolai",
  abstract = "Successful forgetting of unwanted memories is crucial for
              goal-directed behavior and mental wellbeing. While memory
              retention strengthens memory traces, it is unclear what happens
              to memory traces of events that are actively forgotten. Using
              intracranial EEG recordings from lateral temporal cortex, we find
              that memory traces for actively forgotten information are
              partially preserved and exhibit unique neural signatures. Memory
              traces of successfully remembered items show stronger
              encoding-retrieval similarity in gamma frequency patterns. By
              contrast, encoding-retrieval similarity of item-specific memory
              traces of actively forgotten items depend on activity at
              alpha/beta frequencies commonly associated with functional
              inhibition. Additional analyses revealed selective modification
              of item-specific patterns of connectivity and top-down
              information flow from dorsolateral prefrontal cortex to lateral
              temporal cortex in memory traces of intentionally forgotten
              items. These results suggest that intentional forgetting relies
              more on inhibitory top-down connections than intentional
              remembering, resulting in inhibitory memory traces with unique
              neural signatures and representational formats.",
  journal  = "Nat. Commun.",
  volume   =  12,
  number   =  1,
  pages    = "6443",
  month    =  nov,
  year     =  2021,
  language = "en",
  issn     = "2041-1723",
  pmid     = "34750407",
  doi      = "10.1038/s41467-021-26713-x",
  pmc      = "PMC8575985"
}

@ARTICLE{Schilberg2021-sm,
  title    = "{Phase and power modulations on the amplitude of TMS-induced motor
              evoked potentials}",
  author   = "Schilberg, Lukas and Ten Oever, Sanne and Schuhmann, Teresa and
              Sack, Alexander T",
  abstract = "The evaluation of transcranial magnetic stimulation (TMS)-induced
              motor evoked potentials (MEPs) promises valuable information
              about fundamental brain related mechanisms and may serve as a
              diagnostic tool for clinical monitoring of therapeutic progress
              or surgery procedures. However, reports about spontaneous
              fluctuations of MEP amplitudes causing high intra-individual
              variability have led to increased concerns about the reliability
              of this measure. One possible cause for high variability of MEPs
              could be neuronal oscillatory activity, which reflects
              fluctuations of membrane potentials that systematically increase
              and decrease the excitability of neuronal networks. Here, we
              investigate the dependence of MEP amplitude on oscillation power
              and phase by combining the application of single pulse TMS over
              the primary motor cortex with concurrent recordings of
              electromyography and electroencephalography. Our results show
              that MEP amplitude is correlated to alpha phase, alpha power as
              well as beta phase. These findings may help explain corticospinal
              excitability fluctuations by highlighting the modulatory effect
              of alpha and beta phase on MEPs. In the future, controlling for
              such a causal relationship may allow for the development of new
              protocols, improve this method as a (diagnostic) tool and
              increase the specificity and efficacy of general TMS
              applications.",
  journal  = "PLoS One",
  volume   =  16,
  number   =  9,
  pages    = "e0255815",
  month    =  sep,
  year     =  2021,
  file     = "All Papers/S/Schilberg et al. 2021 -plos one - Phase and power modulations on the amplitude of TMS-induced motor evoked potentials.pdf",
  language = "en",
  issn     = "1932-6203",
  pmid     = "34529682",
  doi      = "10.1371/journal.pone.0255815",
  pmc      = "PMC8445484"
}

@ARTICLE{Ten_Oever2021-bc,
  title     = "{An oscillating computational model can track pseudo-rhythmic
               speech by using linguistic predictions}",
  author    = "Ten Oever, Sanne and Martin, Andrea E",
  abstract  = "Neuronal oscillations putatively track speech in order to
               optimize sensory processing. However, it is unclear how
               isochronous brain oscillations can track pseudo-rhythmic speech
               input. Here we propose that oscillations can track
               pseudo-rhythmic speech when considering that speech time is
               dependent on content-based predictions flowing from internal
               language models. We show that temporal dynamics of speech are
               dependent on the predictability of words in a sentence. A
               computational model including oscillations, feedback, and
               inhibition is able to track pseudo-rhythmic speech input. As the
               model processes, it generates temporal phase codes, which are a
               candidate mechanism for carrying information forward in time.
               The model is optimally sensitive to the natural temporal speech
               dynamics and can explain empirical data on temporal speech
               illusions. Our results suggest that speech tracking does not
               have to rely only on the acoustics but could also exploit
               ongoing interactions between oscillations and constraints
               flowing from internal language models.",
  journal   = "Elife",
  publisher = "eLife, 10: e68066",
  volume    =  10,
  month     =  aug,
  year      =  2021,
  file      = "All Papers/T/Ten Oever and Martin 2021 -elife - An oscillating computational model can track pseudo-rhythmic speech by using linguistic predictions.pdf",
  keywords  = "language; neuroscience; none; oscillations; prediction; speech;
               temporal processing",
  language  = "en",
  issn      = "2050-084X",
  pmid      = "34338196",
  doi       = "10.7554/eLife.68066",
  pmc       = "PMC8328513"
}

@ARTICLE{Guest2021-pi,
  title    = "{How Computational Modeling Can Force Theory Building in
              Psychological Science}",
  author   = "Guest, Olivia and Martin, Andrea E",
  abstract = "Psychology endeavors to develop theories of human capacities and
              behaviors on the basis of a variety of methodologies and
              dependent measures. We argue that one of the most divisive
              factors in psychological science is whether researchers choose to
              use computational modeling of theories (over and above data)
              during the scientific-inference process. Modeling is undervalued
              yet holds promise for advancing psychological science. The
              inherent demands of computational modeling guide us toward better
              science by forcing us to conceptually analyze, specify, and
              formalize intuitions that otherwise remain unexamined-what we dub
              open theory. Constraining our inference process through modeling
              enables us to build explanatory and predictive theories. Here, we
              present scientific inference in psychology as a path function in
              which each step shapes the next. Computational modeling can
              constrain these steps, thus advancing scientific inference over
              and above the stewardship of experimental practice (e.g.,
              preregistration). If psychology continues to eschew computational
              modeling, we predict more replicability crises and persistent
              failure at coherent theory building. This is because without
              formal modeling we lack open and transparent theorizing. We also
              explain how to formalize, specify, and implement a computational
              model, emphasizing that the advantages of modeling can be
              achieved by anyone with benefit to all.",
  journal  = "Perspect. Psychol. Sci.",
  volume   =  16,
  number   =  4,
  pages    = "789--802",
  month    =  jul,
  year     =  2021,
  file     = "All Papers/G/Guest and Martin 2021 -perspect psychol sci - How Computational Modeling Can Force Theory Building in Psychological Science.pdf",
  keywords = "computational model; open science; scientific inference;
              theoretical psychology",
  language = "en",
  issn     = "1745-6916, 1745-6924",
  pmid     = "33482070",
  doi      = "10.1177/1745691620970585"
}

@ARTICLE{Puebla2021-qi,
  title     = "{The relational processing limits of classic and contemporary
               neural network models of language processing}",
  author    = "Puebla, Guillermo and Martin, Andrea E and Doumas, Leonidas A A",
  abstract  = "ABSTRACTWhether neural networks can capture relational knowledge
               is a matter of long-standing controversy. Recently, some
               researchers have argued that (1) classic connectionist models
               can handle relational structure and (2) the success of deep
               learning approaches to natural language processing suggests that
               structured representations are unnecessary to model human
               language. We tested the Story Gestalt model, a classic
               connectionist model of text comprehension, and a
               Sequence-to-Sequence with Attention model, a modern deep
               learning architecture for natural language processing. Both
               models were trained to answer questions about stories based on
               abstract thematic roles. Two simulations varied the statistical
               structure of new stories while keeping their relational
               structure intact. The performance of each model fell below
               chance at least under one manipulation. We argue that both
               models fail our tests because they can't perform dynamic
               binding. These results cast doubts on the suitability of
               traditional neural networks for explaining relational reasoning
               and language processing phenomena.",
  journal   = "Language, Cognition and Neuroscience",
  publisher = "Routledge",
  volume    =  36,
  number    =  2,
  pages     = "240--254",
  month     =  feb,
  year      =  2021,
  file      = "All Papers/P/Puebla et al. 2021 -language, cognition and neuroscience - The relationa ... classic and contemporary neural network models of language processing.pdf",
  issn      = "2327-3798",
  doi       = "10.1080/23273798.2020.1821906"
}

@ARTICLE{Doumas2021-df,
  title    = "{A model for learning structured representations of similarity and
              relative magnitude from experience}",
  author   = "Doumas, Leonidas A A and Martin, Andrea E",
  abstract = "How a system represents information tightly constrains the kinds
              of problems it can solve. Humans routinely solve problems that
              appear to require abstract representations of stimulus properties
              and relations. How we acquire such representations has central
              importance in an account of human cognition. We briefly describe
              a theory of how a system can learn invariant responses to
              instances of similarity and relative magnitude, and how
              structured, relational representations can be learned from
              initially unstructured inputs. Two operations, comparing
              distributed representations and learning from the concomitant
              network dynamics in time, underpin the ability to learn these
              representations and to respond to invariance in the environment.
              Comparing analog representations of absolute magnitude produces
              invariant signals that carry information about similarity and
              relative magnitude. We describe how a system can then use this
              information to bootstrap learning structured (i.e., symbolic)
              concepts of relative magnitude from experience without assuming
              such representations a priori.",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  37,
  pages    = "158--166",
  month    =  feb,
  year     =  2021,
  file     = "All Papers/D/Doumas and Martin 2021 -current opinion in behavioral sciences - A model ... representations of similarity and relative magnitude from experience.pdf",
  issn     = "2352-1546",
  doi      = "10.1016/j.cobeha.2021.01.001"
}

@INPROCEEDINGS{Coopmans2021-so,
  title  = "{Structure-(in)dependent interpretation of phrases in humans and
            LSTMs}",
  author = "Coopmans, C W and De Hoop, H and Kaushik, K and Hagoort, P and
            Martin, A E",
  volume =  2021,
  pages  = "459--463",
  series = "Proceedings of the Society for Computation in Linguistics (SCiL",
  year   =  2021
}

@INPROCEEDINGS{Zhang2021-ei,
  title       = "{Electrophysiological signatures of second language multimodal
                 comprehension}",
  booktitle   = "{43rd Annual (virtual) Meeting of the Cognitive Science Society
                 (CogSci 2021)}",
  author      = "Zhang, Ye and Ding, Rong and Frassinelli, Diego and Tuomainen,
                 Jyrki and Klavinskis-Whiting, Sebastian and Vigliocco,
                 Gabriella",
  publisher   = "Cognitive Science Society",
  volume      =  2021,
  pages       = "2971--2977",
  series      = "Proceedings of the 43rd Annual Conference of the Cognitive
                 Science Society (CogSci",
  institution = "Cognitive Science Society",
  year        =  2021,
  address     = "Vienna"
}

@ARTICLE{Kaufeld2020-hu,
  title    = "{Linguistic Structure and Meaning Organize Neural Oscillations
              into a Content-Specific Hierarchy}",
  author   = "Kaufeld, Greta and Bosker, Hans Rutger and Ten Oever, Sanne and
              Alday, Phillip M and Meyer, Antje S and Martin, Andrea E",
  abstract = "Neural oscillations track linguistic information during speech
              comprehension (Ding et al., 2016; Keitel et al., 2018), and are
              known to be modulated by acoustic landmarks and speech
              intelligibility (Doelling et al., 2014; Zoefel and VanRullen,
              2015). However, studies investigating linguistic tracking have
              either relied on non-naturalistic isochronous stimuli or failed
              to fully control for prosody. Therefore, it is still unclear
              whether low-frequency activity tracks linguistic structure during
              natural speech, where linguistic structure does not follow such a
              palpable temporal pattern. Here, we measured
              electroencephalography (EEG) and manipulated the presence of
              semantic and syntactic information apart from the timescale of
              their occurrence, while carefully controlling for the
              acoustic-prosodic and lexical-semantic information in the signal.
              EEG was recorded while 29 adult native speakers (22 women, 7 men)
              listened to naturally spoken Dutch sentences, jabberwocky
              controls with morphemes and sentential prosody, word lists with
              lexical content but no phrase structure, and backward
              acoustically matched controls. Mutual information (MI) analysis
              revealed sensitivity to linguistic content: MI was highest for
              sentences at the phrasal (0.8-1.1 Hz) and lexical (1.9-2.8 Hz)
              timescales, suggesting that the delta-band is modulated by
              lexically driven combinatorial processing beyond prosody, and
              that linguistic content (i.e., structure and meaning) organizes
              neural oscillations beyond the timescale and rhythmicity of the
              stimulus. This pattern is consistent with neurophysiologically
              inspired models of language comprehension (Martin, 2016, 2020;
              Martin and Doumas, 2017) where oscillations encode endogenously
              generated linguistic content over and above exogenous or
              stimulus-driven timing and rhythm information.SIGNIFICANCE
              STATEMENT Biological systems like the brain encode their
              environment not only by reacting in a series of stimulus-driven
              responses, but by combining stimulus-driven information with
              endogenous, internally generated, inferential knowledge and
              meaning. Understanding language from speech is the human
              benchmark for this. Much research focuses on the purely
              stimulus-driven response, but here, we focus on the goal of
              language behavior: conveying structure and meaning. To that end,
              we use naturalistic stimuli that contrast acoustic-prosodic and
              lexical-semantic information to show that, during spoken language
              comprehension, oscillatory modulations reflect computations
              related to inferring structure and meaning from the acoustic
              signal. Our experiment provides the first evidence to date that
              compositional structure and meaning organize the oscillatory
              response, above and beyond prosodic and lexical controls.",
  journal  = "J. Neurosci.",
  volume   =  40,
  number   =  49,
  pages    = "9467--9475",
  month    =  dec,
  year     =  2020,
  file     = "All Papers/K/Kaufeld et al. 2020 -j neurosci - Linguistic Structure and Meaning Organize Neural Oscillations into a Content-Specific Hierarchy.pdf",
  keywords = "combinatorial processing; lexical semantics; mutual information;
              neural oscillations; prosody; sentence comprehension",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "33097640",
  doi      = "10.1523/JNEUROSCI.0302-20.2020",
  pmc      = "PMC7724143"
}

@ARTICLE{Meyer2020-sy,
  title     = "{Synchronous, but not entrained: exogenous and endogenous
               cortical rhythms of speech and language processing}",
  author    = "Meyer, Lars and Sun, Yue and Martin, Andrea E",
  abstract  = "ABSTRACTResearch on speech processing is often focused on a
               phenomenon termed ?entrainment?, whereby the cortex shadows
               rhythmic acoustic information with oscillatory activity.
               Entrainment has been observed to a range of rhythms present in
               speech; in addition, synchronicity with abstract information
               (e.g. syntactic structures) has been observed. Entrainment
               accounts face two challenges: First, speech is not exactly
               rhythmic; second, synchronicity with representations that lack a
               clear acoustic counterpart has been described. We propose that
               apparent entrainment does not always result from acoustic
               information. Rather, internal rhythms may have functionalities
               in the generation of abstract representations and predictions.
               While acoustics may often provide punctate opportunities for
               entrainment, internal rhythms may also live a life of their own
               to infer and predict information, leading to intrinsic
               synchronicity ? not to be counted as entrainment. This
               possibility may open up new research avenues in the psycho? and
               neurolinguistic study of language processing and language
               development.",
  journal   = "Language, Cognition and Neuroscience",
  publisher = "Routledge",
  volume    =  35,
  number    =  9,
  pages     = "1089--1099",
  month     =  nov,
  year      =  2020,
  file      = "All Papers/M/Meyer et al. 2020 - Synchronous, but not entrained - exogenous and endogenous cortical rhythms of speech and language processing.pdf;All Papers/M/Meyer et al. 2020 -language, cognition and neuroscience - Synchronous, b ... ous and endogenous cortical rhythms of speech and language processing.pdf",
  issn      = "2327-3798",
  doi       = "10.1080/23273798.2019.1693050"
}

@ARTICLE{Meyer2020-oz,
  title     = "{``Entraining'' to speech, generating language?}",
  author    = "Meyer, Lars and Sun, Yue and Martin, Andrea E",
  abstract  = "ABSTRACTCould meaning be read from acoustics, or from the
               refraction rate of pyramidal cells innervated by the cochlea,
               everyone would be an omniglot. Speech does not contain
               sufficient acoustic cues to identify linguistic units such as
               morphemes, words, and phrases without prior knowledge. Our
               target article (Meyer, L., Sun, Y., \& Martin, A. E. (2019).
               Synchronous, but not entrained: Exogenous and endogenous
               cortical rhythms of speech and language processing. Language,
               Cognition and Neuroscience, 1?11.
               https://doi.org/10.1080/23273798.2019.1693050) thus questioned
               the concept of ?entrainment? of neural oscillations to such
               units. We suggested that synchronicity with these points to the
               existence of endogenous functional ?oscillators??or population
               rhythmic activity in Giraud?s (2020) terms?that underlie the
               inference, generation, and prediction of linguistic units. Here,
               we address a series of inspirational commentaries by our
               colleagues. As apparent from these, some issues raised by our
               target article have already been raised in the literature.
               Psycho? and neurolinguists might still benefit from our reply,
               as ?oscillations are an old concept in vision and motor
               functions, but a new one in linguistics? (Giraud, A.-L. 2020.
               Oscillations for all A commentary on Meyer, Sun \& Martin
               (2020). Language, Cognition and Neuroscience, 1?8).",
  journal   = "Language, Cognition and Neuroscience",
  publisher = "Routledge",
  volume    =  35,
  number    =  9,
  pages     = "1138--1148",
  month     =  nov,
  year      =  2020,
  file      = "All Papers/M/Meyer et al. 2020 - ``Entraining'' to speech, generating language.pdf;All Papers/M/Meyer et al. 2020 -language, cognition and neuroscience - ``Entraining'' to speech, generating language.pdf",
  issn      = "2327-3798",
  doi       = "10.1080/23273798.2020.1827155"
}

@ARTICLE{Cutter2020-ru,
  title    = "{Readers detect an low-level phonological violation between two
              parafoveal words}",
  author   = "Cutter, Michael G and Martin, Andrea E and Sturt, Patrick",
  abstract = "In two eye-tracking studies we investigated whether readers can
              detect a violation of the phonological-grammatical convention for
              the indefinite article an to be followed by a word beginning with
              a vowel when these two words appear in the parafovea. Across two
              experiments participants read sentences in which the word an was
              followed by a parafoveal preview that was either correct (e.g.
              Icelandic), incorrect and represented a phonological violation
              (e.g. Mongolian), or incorrect without representing a
              phonological violation (e.g. Ethiopian), with this parafoveal
              preview changing to the target word as participants made a
              saccade into the space preceding an. Our data suggests that
              participants detected the phonological violation while the target
              word was still two words to the right of fixation, with
              participants making more regressions from the previewed word and
              having longer go-past times on this word when they received a
              violation preview as opposed to a non-violation preview. We argue
              that participants were attempting to perform aspects of sentence
              integration on the basis of low-level orthographic information
              from the previewed word.",
  journal  = "Cognition",
  volume   =  204,
  pages    = "104395",
  month    =  nov,
  year     =  2020,
  keywords = "Contextual fit effects; Parafoveal processing; Phonological
              processing; Reading; n + 2 preview benefit",
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "32682152",
  doi      = "10.1016/j.cognition.2020.104395"
}

@ARTICLE{Coopmans2020-ma,
  title     = "{Incremental structure building of preverbal PPs in Dutch}",
  author    = "Coopmans, Cas W and Schoenmakers, Gert-Jan",
  abstract  = "Abstract Incremental comprehension of head-final constructions
               can reveal structural attachment preferences for ambiguous
               phrases. This study investigates how temporarily ambiguous PPs
               are processed in Dutch verb-final constructions. In De aannemer
               heeft op het dakterras bespaard/gewerkt `The contractor has on
               the roof terrace saved/worked', the PP is locally ambiguous
               between attachment as argument and as adjunct. This ambiguity is
               resolved by the sentence-final verb. In a self-paced reading
               task, we manipulated the argument/adjunct status of the PP, and
               its position relative to the verb. While we found no
               reading-time differences between argument and adjunct PPs, we
               did find that transitive verbs, for which the PP is an argument,
               were read more slowly than intransitive verbs, for which the PP
               is an adjunct. We suggest that Dutch parsers have a preference
               for adjunct attachment of preverbal PPs, and discuss our
               findings in terms of incremental parsing models that aim to
               minimize costly reanalysis.",
  journal   = "Linguistics in the Netherlands",
  publisher = "John Benjamins",
  volume    =  37,
  number    =  1,
  pages     = "38--52",
  month     =  oct,
  year      =  2020,
  issn      = "0929-7332, 1569-9919",
  doi       = "10.1075/avt.00036.coo"
}

@ARTICLE{Kaufeld2020-mn,
  title     = "{Contextual speech rate influences morphosyntactic prediction and
               integration}",
  author    = "Kaufeld, Greta and Naumann, Wibke and Meyer, Antje S and Bosker,
               Hans Rutger and Martin, Andrea E",
  abstract  = "ABSTRACTUnderstanding spoken language requires the integration
               and weighting of multiple cues, and may call on cue integration
               mechanisms that have been studied in other areas of perception.
               In the current study, we used eye-tracking (visual-world
               paradigm) to examine how contextual speech rate (a lower-level,
               perceptual cue) and morphosyntactic knowledge (a higher-level,
               linguistic cue) are iteratively combined and integrated. Results
               indicate that participants used contextual rate information
               immediately, which we interpret as evidence of perceptual
               inference and the generation of predictions about upcoming
               morphosyntactic information. Additionally, we observed that
               early rate effects remained active in the presence of later
               conflicting lexical information. This result demonstrates that
               (1) contextual speech rate functions as a cue to morphosyntactic
               inferences, even in the presence of subsequent disambiguating
               information; and (2) listeners iteratively use multiple sources
               of information to draw inferences and generate predictions
               during speech comprehension. We discuss the implication of these
               demonstrations for theories of language processing.",
  journal   = "Language, Cognition and Neuroscience",
  publisher = "Routledge",
  volume    =  35,
  number    =  7,
  pages     = "933--948",
  month     =  sep,
  year      =  2020,
  issn      = "2327-3798",
  doi       = "10.1080/23273798.2019.1701691"
}

@ARTICLE{Cutter2020-zu,
  title    = "{The activation of contextually predictable words in syntactically
              illegal positions}",
  author   = "Cutter, Michael G and Martin, Andrea E and Sturt, Patrick",
  abstract = "We present an eye-tracking study testing a hypothesis emerging
              from several theories of prediction during language processing,
              whereby predictable words should be skipped more than
              unpredictable words even in syntactically illegal positions.
              Participants read sentences in which a target word became
              predictable by a certain point (e.g., ``bone'' is 92\%
              predictable given, ``The dog buried his. . .''), with the next
              word actually being an intensifier (e.g., ``really''), which a
              noun cannot follow. The target noun remained predictable to
              appear later in the sentence. We used the boundary paradigm to
              present the predictable noun or an alternative unpredictable noun
              (e.g., ``food'') directly after the intensifier, until
              participants moved beyond the intensifier, at which point the
              noun changed to a syntactically legal word. Participants also
              read sentences in which predictable or unpredictable nouns
              appeared in syntactically legal positions. A Bayesian
              linear-mixed model suggested a 5.7\% predictability effect on
              skipping of nouns in syntactically legal positions, and a 3.1\%
              predictability effect on skipping of nouns in illegal positions.
              We discuss our findings in relation to theories of lexical
              prediction during reading.",
  journal  = "Q. J. Exp. Psychol.",
  volume   =  73,
  number   =  9,
  pages    = "1423--1430",
  month    =  sep,
  year     =  2020,
  keywords = "Language prediction; eye movements; word skipping",
  language = "en",
  issn     = "1747-0218, 1747-0226",
  pmid     = "32075497",
  doi      = "10.1177/1747021820911021"
}

@ARTICLE{Martin2020-ea,
  title    = "{A Compositional Neural Architecture for Language}",
  author   = "Martin, Andrea E",
  abstract = "Hierarchical structure and compositionality imbue human language
              with unparalleled expressive power and set it apart from other
              perception-action systems. However, neither formal nor
              neurobiological models account for how these defining
              computational properties might arise in a physiological system. I
              attempt to reconcile hierarchy and compositionality with
              principles from cell assembly computation in neuroscience; the
              result is an emerging theory of how the brain could convert
              distributed perceptual representations into hierarchical
              structures across multiple timescales while representing
              interpretable incremental stages of (de)compositional meaning.
              The model's architecture-a multidimensional coordinate system
              based on neurophysiological models of sensory processing-proposes
              that a manifold of neural trajectories encodes sensory, motor,
              and abstract linguistic states. Gain modulation, including
              inhibition, tunes the path in the manifold in accordance with
              behavior and is how latent structure is inferred. As a
              consequence, predictive information about upcoming sensory input
              during production and comprehension is available without a
              separate operation. The proposed processing mechanism is
              synthesized from current models of neural entrainment to speech,
              concepts from systems neuroscience and category theory, and a
              symbolic-connectionist computational model that uses time and
              rhythm to structure information. I build on evidence from
              cognitive neuroscience and computational modeling that suggests a
              formal and mechanistic alignment between structure building and
              neural oscillations, and moves toward unifying basic insights
              from linguistics and psycholinguistics with the currency of
              neural computation.",
  journal  = "J. Cogn. Neurosci.",
  volume   =  32,
  number   =  8,
  pages    = "1407--1427",
  month    =  aug,
  year     =  2020,
  file     = "All Papers/M/Martin 2020 - A Compositional Neural Architecture for Language.pdf;All Papers/M/Martin 2020 -j cogn neurosci - A Compositional Neural Architecture for Language.pdf",
  language = "en",
  issn     = "0898-929X, 1530-8898",
  pmid     = "32108553",
  doi      = "10.1162/jocn\_a\_01552"
}

@ARTICLE{Ten_Oever2020-lf,
  title    = "{Phase-Coded Oscillatory Ordering Promotes the Separation of
              Closely Matched Representations to Optimize Perceptual
              Discrimination}",
  author   = "Ten Oever, Sanne and Meierdierks, Tobias and Duecker, Felix and
              De Graaf, Tom A and Sack, Alexander T",
  abstract = "Low-frequency oscillations are proposed to be involved in
              separating neuronal representations belonging to different items.
              Although item-specific neuronal activity was found to cluster on
              different oscillatory phases, the influence of this mechanism on
              perception is unknown. Here, we investigated the perceptual
              consequences of neuronal item separation through oscillatory
              clustering. In an electroencephalographic experiment,
              participants categorized sounds parametrically varying in pitch,
              relative to an arbitrary pitch boundary. Pre-stimulus theta and
              alpha phase biased near-boundary sound categorization to one
              category or the other. Phase also modulated whether evoked
              neuronal responses contributed stronger to the fit of the sound
              envelope of one or another category. Intriguingly, participants
              with stronger oscillatory clustering (phase strongly biasing
              sound categorization) in the theta, but not alpha, range had
              steeper perceptual psychometric slopes (sharper sound category
              discrimination). These results indicate that neuronal sorting by
              phase directly influences subsequent perception and has a
              positive impact on discrimination performance.",
  journal  = "iScience",
  volume   =  23,
  number   =  7,
  pages    = "101282",
  month    =  jul,
  year     =  2020,
  file     = "All Papers/T/Ten Oever et al. 2020 -iscience - Phase-Coded Oscillatory Ordering Promo ... Closely Matched Representations to Optimize Perceptual Discrimination.pdf",
  keywords = "Behavioral Neuroscience; Cognitive Neuroscience; Neuroscience",
  language = "en",
  issn     = "2589-0042",
  pmid     = "32604063",
  doi      = "10.1016/j.isci.2020.101282",
  pmc      = "PMC7326734"
}

@ARTICLE{Cutter2020-ea,
  title    = "{Capitalization interacts with syntactic complexity}",
  author   = "Cutter, Michael G and Martin, Andrea E and Sturt, Patrick",
  abstract = "We investigated whether readers use the low-level cue of proper
              noun capitalization in the parafovea to infer syntactic category,
              and whether this results in an early update of the representation
              of a sentence's syntactic structure. Participants read sentences
              containing either a subject relative or object relative clause,
              in which the relative clause's overt argument was a proper noun
              (e.g., The tall lanky guard who alerted Charlie/Charlie alerted
              to the danger was young) across three experiments. In Experiment
              1 these sentences were presented in normal sentence casing or
              entirely in upper case. In Experiment 2 participants received
              either valid or invalid parafoveal previews of the relative
              clause. In Experiment 3 participants viewed relative clauses in
              only normal conditions. We hypothesized that we would observe
              relative clause effects (i.e., inflated fixation times for object
              relative clauses) while readers were still fixated on the word
              who, if readers use capitalization to infer a parafoveal word's
              syntactic class. This would constitute a syntactic
              parafoveal-on-foveal effect. Furthermore, we hypothesized that
              this effect should be influenced by sentence casing in Experiment
              1 (with no cue for syntactic category being available in upper
              case sentences) but not by parafoveal preview validity of the
              target words. We observed syntactic parafoveal-on-foveal effects
              in Experiment 1 and 3, and a Bayesian analysis of the combined
              data from all three experiments. These effects seemed to be
              influenced more by noun capitalization than lexical processing.
              We discuss our findings in relation to models of eye movement
              control and sentence processing theories. (PsycInfo Database
              Record (c) 2020 APA, all rights reserved).",
  journal  = "J. Exp. Psychol. Learn. Mem. Cogn.",
  volume   =  46,
  number   =  6,
  pages    = "1146--1164",
  month    =  jun,
  year     =  2020,
  language = "en",
  issn     = "0278-7393, 1939-1285",
  pmid     = "31621360",
  doi      = "10.1037/xlm0000780"
}

@ARTICLE{Ten_Oever2020-ll,
  title    = "{Phase-dependent amplification of working memory content and
              performance}",
  author   = "Ten Oever, Sanne and De Weerd, Peter and Sack, Alexander T",
  abstract = "Successful working memory performance has been related to
              oscillatory mechanisms operating in low-frequency ranges. Yet,
              their mechanistic interaction with the distributed neural
              activity patterns representing the content of the memorized
              information remains unclear. Here, we record EEG during a working
              memory retention interval, while a task-irrelevant,
              high-intensity visual impulse stimulus is presented to boost the
              read-out of distributed neural activity related to the content
              held in working memory. Decoding of this activity with a linear
              classifier reveals significant modulations of classification
              accuracy by oscillatory phase in the theta/alpha ranges at the
              moment of impulse presentation. Additionally, behavioral accuracy
              is highest at the phases showing maximized decoding accuracy. At
              those phases, behavioral accuracy is higher in trials with the
              impulse compared to no-impulse trials. This constitutes the first
              evidence in humans that working memory information is maximized
              within limited phase ranges, and that phase-selective, sensory
              impulse stimulation can improve working memory.",
  journal  = "Nat. Commun.",
  volume   =  11,
  number   =  1,
  pages    = "1832",
  month    =  apr,
  year     =  2020,
  language = "en",
  issn     = "2041-1723",
  pmid     = "32286288",
  doi      = "10.1038/s41467-020-15629-7",
  pmc      = "PMC7156664"
}

@ARTICLE{Kaufeld2020-ay,
  title    = "{Knowledge-based and signal-based cues are weighted flexibly
              during spoken language comprehension}",
  author   = "Kaufeld, Greta and Ravenschlag, Anna and Meyer, Antje S and
              Martin, Andrea E and Bosker, Hans Rutger",
  abstract = "During spoken language comprehension, listeners make use of both
              knowledge-based and signal-based sources of information, but
              little is known about how cues from these distinct levels of
              representational hierarchy are weighted and integrated online. In
              an eye-tracking experiment using the visual world paradigm, we
              investigated the flexible weighting and integration of
              morphosyntactic gender marking (a knowledge-based cue) and
              contextual speech rate (a signal-based cue). We observed that
              participants used the morphosyntactic cue immediately to make
              predictions about upcoming referents, even in the presence of
              uncertainty about the cue's reliability. Moreover, we found
              speech rate normalization effects in participants' gaze patterns
              even in the presence of preceding morphosyntactic information.
              These results demonstrate that cues are weighted and integrated
              flexibly online, rather than adhering to a strict hierarchy. We
              further found rate normalization effects in the looking behavior
              of participants who showed a strong behavioral preference for the
              morphosyntactic gender cue. This indicates that rate
              normalization effects are robust and potentially automatic. We
              discuss these results in light of theories of cue integration and
              the two-stage model of acoustic context effects. (PsycINFO
              Database Record (c) 2020 APA, all rights reserved).",
  journal  = "J. Exp. Psychol. Learn. Mem. Cogn.",
  volume   =  46,
  number   =  3,
  pages    = "549--562",
  month    =  mar,
  year     =  2020,
  file     = "All Papers/K/Kaufeld et al. 2020 -j exp psychol learn mem cogn - Knowledge-based and ... based cues are weighted flexibly during spoken language comprehension.pdf",
  language = "en",
  issn     = "0278-7393, 1939-1285",
  pmid     = "31343252",
  doi      = "10.1037/xlm0000744"
}

@ARTICLE{Martin2020-kl,
  title    = "{Modelling meaning composition from formalism to mechanism}",
  author   = "Martin, Andrea E and Baggio, Giosu{\`e}",
  abstract = "Human thought and language have extraordinary expressive power
              because meaningful parts can be assembled into more complex
              semantic structures. This partly underlies our ability to compose
              meanings into endlessly novel configurations, and sets us apart
              from other species and current computing devices. Crucially,
              human behaviour, including language use and linguistic data,
              indicates that composing parts into complex structures does not
              threaten the existence of constituent parts as independent units
              in the system: parts and wholes exist simultaneously yet
              independently from one another in the mind and brain. This
              independence is evident in human behaviour, but it seems at odds
              with what is known about the brain's exquisite sensitivity to
              statistical patterns: everyday language use is productive and
              expressive precisely because it can go beyond statistical
              regularities. Formal theories in philosophy and linguistics
              explain this fact by assuming that language and thought are
              compositional: systems of representations that separate a
              variable (or role) from its values (fillers), such that the
              meaning of a complex expression is a function of the values
              assigned to the variables. The debate on whether and how
              compositional systems could be implemented in minds, brains and
              machines remains vigorous. However, it has not yet resulted in
              mechanistic models of semantic composition: how, then, are the
              constituents of thoughts and sentences put and held together? We
              review and discuss current efforts at understanding this problem,
              and we chart possible routes for future research. This article is
              part of the theme issue 'Towards mechanistic models of meaning
              composition'.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  375,
  number   =  1791,
  pages    = "20190298",
  month    =  feb,
  year     =  2020,
  file     = "All Papers/M/Martin and Baggio 2020 -philos trans r soc lond b biol sci - Modelling meaning composition from formalism to mechanism.pdf",
  keywords = "cognition; compositionality; language; mechanistic models;
              neuroscience; semantics",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "31840588",
  doi      = "10.1098/rstb.2019.0298",
  pmc      = "PMC6939358"
}

@ARTICLE{Martin2020-hg,
  title    = "{Tensors and compositionality in neural systems}",
  author   = "Martin, Andrea E and Doumas, Leonidas A A",
  abstract = "Neither neurobiological nor process models of meaning composition
              specify the operator through which constituent parts are bound
              together into compositional structures. In this paper, we argue
              that a neurophysiological computation system cannot achieve the
              compositionality exhibited in human thought and language if it
              were to rely on a multiplicative operator to perform binding, as
              the tensor product (TP)-based systems that have been widely
              adopted in cognitive science, neuroscience and artificial
              intelligence do. We show via simulation and two behavioural
              experiments that TPs violate variable-value independence, but
              human behaviour does not. Specifically, TPs fail to capture that
              in the statements fuzzy cactus and fuzzy penguin, both cactus and
              penguin are predicated by fuzzy(x) and belong to the set of fuzzy
              things, rendering these arguments similar to each other.
              Consistent with that thesis, people judged arguments that shared
              the same role to be similar, even when those arguments themselves
              (e.g., cacti and penguins) were judged to be dissimilar when in
              isolation. By contrast, the similarity of the TPs representing
              fuzzy(cactus) and fuzzy(penguin) was determined by the similarity
              of the arguments, which in this case approaches zero. Based on
              these results, we argue that neural systems that use TPs for
              binding cannot approximate how the human mind and brain represent
              compositional information during processing. We describe a
              contrasting binding mechanism that any physiological or
              artificial neural system could use to maintain independence
              between a role and its argument, a prerequisite for
              compositionality and, thus, for instantiating the expressive
              power of human thought and language in a neural system. This
              article is part of the theme issue 'Towards mechanistic models of
              meaning composition'.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  375,
  number   =  1791,
  pages    = "20190306",
  month    =  feb,
  year     =  2020,
  file     = "All Papers/M/Martin and Doumas 2020 -philos trans r soc lond b biol sci - Tensors and compositionality in neural systems.pdf",
  keywords = "binding; compositionality; concepts; language; predicates; tensor
              products",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "31840579",
  doi      = "10.1098/rstb.2019.0306",
  pmc      = "PMC6939350"
}

@ARTICLE{Brennan2020-vk,
  title    = "{Phase synchronization varies systematically with linguistic
              structure composition}",
  author   = "Brennan, Jonathan R and Martin, Andrea E",
  abstract = "Computation in neuronal assemblies is putatively reflected in the
              excitatory and inhibitory cycles of activation distributed
              throughout the brain. In speech and language processing,
              coordination of these cycles resulting in phase synchronization
              has been argued to reflect the integration of information on
              different timescales (e.g. segmenting acoustics signals to
              phonemic and syllabic representations; (Giraud and Poeppel 2012
              Nat. Neurosci. 15, 511 (doi:10.1038/nn.3063)). A natural
              extension of this claim is that phase synchronization functions
              similarly to support the inference of more abstract higher-level
              linguistic structures (Martin 2016 Front. Psychol. 7, 120; Martin
              and Doumas 2017 PLoS Biol. 15, e2000663
              (doi:10.1371/journal.pbio.2000663); Martin and Doumas. 2019 Curr.
              Opin. Behav. Sci. 29, 77-83 (doi:10.1016/j.cobeha.2019.04.008)).
              Hale et al. (Hale et al. 2018 Finding syntax in human
              encephalography with beam search. arXiv 1806.04127
              (http://arxiv.org/abs/1806.04127)) showed that syntactically
              driven parsing decisions predict electroencephalography (EEG)
              responses in the time domain; here we ask whether phase
              synchronization in the form of either inter-trial phrase
              coherence or cross-frequency coupling (CFC) between
              high-frequency (i.e. gamma) bursts and lower-frequency carrier
              signals (i.e. delta, theta), changes as the linguistic structures
              of compositional meaning (viz., bracket completions, as denoted
              by the onset of words that complete phrases) accrue. We use a
              naturalistic story-listening EEG dataset from Hale et al. to
              assess the relationship between linguistic structure and phase
              alignment. We observe increased phase synchronization as a
              function of phrase counts in the delta, theta, and gamma bands,
              especially for function words. A more complex pattern emerged for
              CFC as phrase count changed, possibly related to the lack of a
              one-to-one mapping between 'size' of linguistic structure and
              frequency band-an assumption that is tacit in recent frameworks.
              These results emphasize the important role that phase
              synchronization, desynchronization, and thus, inhibition, play in
              the construction of compositional meaning by distributed neural
              networks in the brain. This article is part of the theme issue
              'Towards mechanistic models of meaning composition'.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  375,
  number   =  1791,
  pages    = "20190305",
  month    =  feb,
  year     =  2020,
  file     = "All Papers/B/Brennan and Martin 2020 -philos trans r soc lond b biol sci - Phase synchronization varies systematically with linguistic structure composition.pdf",
  keywords = "compositionality; electroencephalography; language; naturalistic
              language processing; neural oscillations; phase synchronization",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "31840584",
  doi      = "10.1098/rstb.2019.0305",
  pmc      = "PMC6939345"
}

@INPROCEEDINGS{Doumas2020-dz,
  title       = "{Relation learning in a neurocomputational architecture
                 supports cross-domain transfer}",
  booktitle   = "{the 42nd Annual Virtual Meeting of the Cognitive Science
                 Society (CogSci 2020)}",
  author      = "Doumas, Leonidas A A and Martin, Andrea E and Hummel, John E",
  publisher   = "Cognitive Science Society",
  volume      =  2020,
  pages       = "932--937",
  series      = "Proceedings of the 42nd Annual Virtual Meeting of the
                 Cognitive Science Society (CogSci",
  institution = "Cognitive Science Society",
  year        =  2020,
  address     = "Montreal, QB"
}

@INPROCEEDINGS{Hashemzadeh2020-fm,
  title      = "{From language to language-ish: How brain-like is an LSTM's
                representation of nonsensical language stimuli?}",
  booktitle  = "{Findings of the Association for Computational Linguistics:
                EMNLP 2020}",
  author     = "Hashemzadeh, Maryam and Kaufeld, Greta and White, Martha and
                Martin, Andrea E and Fyshe, Alona",
  publisher  = "Association for Computational Linguistics",
  pages      = "645--655",
  series     = "Liu (Eds.), Findings of the Association for Computational
                Linguistics: EMNLP 2020",
  year       =  2020,
  address    = "Stroudsburg, PA, USA",
  conference = "Findings of the Association for Computational Linguistics:
                EMNLP 2020",
  location   = "Online",
  doi        = "10.18653/v1/2020.findings-emnlp.57"
}

@ARTICLE{Martin2019-oh,
  title    = "{Predicate learning in neural systems: using oscillations to
              discover latent structure}",
  author   = "Martin, Andrea E and Doumas, Leonidas A A",
  abstract = "Humans learn to represent complex structures (e.g. natural
              language, music, mathematics) from experience with their
              environments. Often such structures are latent, hidden, or not
              encoded in statistics about sensory representations alone.
              Accounts of human cognition have long emphasized the importance
              of structured representations, yet the majority of contemporary
              neural networks do not learn structure from experience. Here, we
              describe one way that structured, functionally symbolic
              representations can be instantiated in an artificial neural
              network. Then, we describe how such latent structures (viz.
              predicates) can be learned from experience with unstructured
              data. Our approach exploits two principles from psychology and
              neuroscience: comparison of representations, and the naturally
              occurring dynamic properties of distributed computing across
              neuronal assemblies (viz. neural oscillations). We discuss how
              the ability to learn predicates from experience, to represent
              information compositionally, and to extrapolate knowledge to
              unseen data is core to understanding and modeling the most
              complex human behaviors (e.g. relational reasoning, analogy,
              language processing, game play).",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  29,
  pages    = "77--83",
  month    =  oct,
  year     =  2019,
  file     = "All Papers/M/Martin and Doumas 2019 -current opinion in behavioral sciences - Predica ... g in neural systems - using oscillations to discover latent structure.pdf",
  issn     = "2352-1546",
  doi      = "10.1016/j.cobeha.2019.04.008"
}

@ARTICLE{Ito2017-at,
  title     = "{How robust are prediction effects in language comprehension?
               Failure to replicate article-elicited N400 effects}",
  author    = "Ito, Aine and Martin, Andrea E and Nieuwland, Mante S",
  abstract  = "Current psycholinguistic theory proffers prediction as a
               central, explanatory mechanism in language processing. However,
               widely-replicated prediction effects may not mean that
               prediction is necessary in language processing. As a case in
               point, C. D. Martin et al. [2013. Bilinguals reading in their
               second language do not predict upcoming words as native readers
               do.",
  journal   = "Lang. Cogn. Neurosci.",
  publisher = "Informa UK Limited",
  volume    =  32,
  number    =  8,
  pages     = "954--965",
  month     =  sep,
  year      =  2017,
  file      = "All Papers/I/Ito et al. 2017 -lang cogn neurosci - How robust are prediction effects ... ge comprehension - Failure to replicate article-elicited N400 effects.pdf",
  language  = "en",
  issn      = "2327-3798, 2327-3801",
  doi       = "10.1080/23273798.2016.1242761"
}

@ARTICLE{Martin2017-qf,
  title    = "{Prediction of Agreement and Phonetic Overlap Shape Sublexical
              Identification}",
  author   = "Martin, Andrea E and Monahan, Philip J and Samuel, Arthur G",
  abstract = "The mapping between the physical speech signal and our internal
              representations is rarely straightforward. When faced with
              uncertainty, higher-order information is used to parse the signal
              and because of this, the lexicon and some aspects of sentential
              context have been shown to modulate the identification of
              ambiguous phonetic segments. Here, using a phoneme identification
              task (i.e., participants judged whether they heard [o] or [a] at
              the end of an adjective in a noun-adjective sequence), we asked
              whether grammatical gender cues influence phonetic identification
              and if this influence is shaped by the phonetic properties of the
              agreeing elements. In three experiments, we show that
              phrase-level gender agreement in Spanish affects the
              identification of ambiguous adjective-final vowels. Moreover,
              this effect is strongest when the phonetic characteristics of the
              element triggering agreement and the phonetic form of the
              agreeing element are identical. Our data are consistent with
              models wherein listeners generate specific predictions based on
              the interplay of underlying morphosyntactic knowledge and surface
              phonetic cues.",
  journal  = "Lang. Speech",
  volume   =  60,
  number   =  3,
  pages    = "356--376",
  series   = "equal authorship contribution, alphabetical listing",
  month    =  sep,
  year     =  2017,
  keywords = "Prediction; Spanish; grammatical gender agreement; phoneme
              identification; sentence processing; speech perception",
  language = "en",
  issn     = "0023-8309",
  pmid     = "28915783",
  doi      = "10.1177/0023830916650714"
}

@ARTICLE{Martin2017-lz,
  title    = "{A mechanism for the cortical computation of hierarchical
              linguistic structure}",
  author   = "Martin, Andrea E and Doumas, Leonidas A A",
  abstract = "Biological systems often detect species-specific signals in the
              environment. In humans, speech and language are species-specific
              signals of fundamental biological importance. To detect the
              linguistic signal, human brains must form hierarchical
              representations from a sequence of perceptual inputs distributed
              in time. What mechanism underlies this ability? One hypothesis is
              that the brain repurposed an available neurobiological mechanism
              when hierarchical linguistic representation became an efficient
              solution to a computational problem posed to the organism. Under
              such an account, a single mechanism must have the capacity to
              perform multiple, functionally related computations, e.g., detect
              the linguistic signal and perform other cognitive functions,
              while, ideally, oscillating like the human brain. We show that a
              computational model of analogy, built for an entirely different
              purpose-learning relational reasoning-processes sentences,
              represents their meaning, and, crucially, exhibits oscillatory
              activation patterns resembling cortical signals elicited by the
              same stimuli. Such redundancy in the cortical and machine signals
              is indicative of formal and mechanistic alignment between
              representational structure building and ``cortical''
              oscillations. By inductive inference, this synergy suggests that
              the cortical signal reflects structure generation, just as the
              machine signal does. A single mechanism-using time to encode
              information across a layered network-generates the kind of
              (de)compositional representational hierarchy that is crucial for
              human language and offers a mechanistic linking hypothesis
              between linguistic representation and cortical computation.",
  journal  = "PLoS Biol.",
  volume   =  15,
  number   =  3,
  pages    = "e2000663",
  month    =  mar,
  year     =  2017,
  file     = "All Papers/M/Martin and Doumas 2017 -plos biol - A mechanism for the cortical computation of hierarchical linguistic structure.pdf",
  language = "en",
  issn     = "1544-9173, 1545-7885",
  pmid     = "28253256",
  doi      = "10.1371/journal.pbio.2000663",
  pmc      = "PMC5333798"
}

@ARTICLE{Martin2016-sr,
  title    = "{Language Processing as Cue Integration: Grounding the Psychology
              of Language in Perception and Neurophysiology}",
  author   = "Martin, Andrea E",
  abstract = "I argue that cue integration, a psychophysiological mechanism
              from vision and multisensory perception, offers a computational
              linking hypothesis between psycholinguistic theory and
              neurobiological models of language. I propose that this
              mechanism, which incorporates probabilistic estimates of a cue's
              reliability, might function in language processing from the
              perception of a phoneme to the comprehension of a phrase
              structure. I briefly consider the implications of the cue
              integration hypothesis for an integrated theory of language that
              includes acquisition, production, dialogue and bilingualism,
              while grounding the hypothesis in canonical neural computation.",
  journal  = "Front. Psychol.",
  volume   =  7,
  pages    = "120",
  month    =  feb,
  year     =  2016,
  file     = "All Papers/M/Martin 2016 -front psychol - Language Processing as Cue Integration - Grounding the Psychology of Language in Perception and Neurophysiology.pdf",
  keywords = "cue integration; cue-based retrieval; language comprehension;
              neurobiology of language; sentence processing",
  language = "en",
  issn     = "1664-1078",
  pmid     = "26909051",
  doi      = "10.3389/fpsyg.2016.00120",
  pmc      = "PMC4754405"
}

@INPROCEEDINGS{Doumas2016-om,
  title       = "{Abstraction in time: Finding hierarchical linguistic structure
                 in a model of relational processing}",
  booktitle   = "{38th Annual Conference of the Cognitive Science Society
                 (CogSci 2016)}",
  author      = "Doumas, Leonidas A A and Martin, Andrea E",
  pages       = "2279--2284",
  series      = "Proceedings of the 38th Annual Conference of the Cognitive
                 Science Society",
  institution = "Cognitive Science Society",
  year        =  2016,
  file        = "All Papers/D/Doumas and Martin 2016 - Abstraction in time - Finding hierarchical linguistic structure in a model of relational processing.pdf"
}

@ARTICLE{Martin2014-zg,
  title    = "{Agreement attraction during comprehension of grammatical
              sentences: ERP evidence from ellipsis}",
  author   = "Martin, Andrea E and Nieuwland, Mante S and Carreiras, Manuel",
  abstract = "Successful dependency resolution during language comprehension
              relies on accessing certain representations in memory, and not
              others. We recently reported event-related potential (ERP)
              evidence that syntactically unavailable, intervening
              attractor-nouns interfered during comprehension of Spanish
              noun-phrase ellipsis (the determiner otra/otro): grammatically
              correct determiners that mismatched the gender of attractor-nouns
              elicited a sustained negativity as also observed for incorrect
              determiners (Martin, Nieuwland, \& Carreiras, 2012). The current
              study sought to extend this novel finding in sentences containing
              object-extracted relative clauses, where the antecedent may be
              less prominent. Whereas correct determiners that matched the
              gender of attractor-nouns now elicited an early anterior
              negativity as also observed for mismatching determiners, the
              previously reported interaction pattern was replicated in P600
              responses to subsequent words. Our results suggest that
              structural and gender information is simultaneously taken into
              account, providing further evidence for retrieval interference
              during comprehension of grammatical sentences.",
  journal  = "Brain Lang.",
  volume   =  135,
  pages    = "42--51",
  month    =  aug,
  year     =  2014,
  keywords = "Agreement attraction; Anterior negativity; ERPs; Ellipsis;
              Interference; Memory; NRef; P600; Retrieval cues; Sentence
              processing",
  language = "en",
  issn     = "0093-934X, 1090-2155",
  pmid     = "24911918",
  doi      = "10.1016/j.bandl.2014.05.001"
}

@ARTICLE{Nieuwland2013-hk,
  title    = "{Event-related brain potential evidence for animacy processing
              asymmetries during sentence comprehension}",
  author   = "Nieuwland, Mante S and Martin, Andrea E and Carreiras, Manuel",
  abstract = "The animacy distinction is deeply rooted in the language faculty.
              A key example is differential object marking, the phenomenon
              where animate sentential objects receive specific marking. We
              used event-related potentials to examine the neural processing
              consequences of case-marking violations on animate and inanimate
              direct objects in Spanish. Inanimate objects with incorrect
              prepositional case marker 'a' ('al suelo') elicited a P600 effect
              compared to unmarked objects, consistent with previous
              literature. However, animate objects without the required
              prepositional case marker ('el obispo') only elicited an N400
              effect compared to marked objects. This novel finding, an
              exclusive N400 modulation by a straightforward grammatical rule
              violation, does not follow from extant neurocognitive models of
              sentence processing, and mirrors unexpected ``semantic P600''
              effects for thematically problematic sentences. These results may
              reflect animacy asymmetry in competition for argument prominence:
              following the article, thematic interpretation difficulties are
              elicited only by unexpectedly animate objects.",
  journal  = "Brain Lang.",
  volume   =  126,
  number   =  2,
  pages    = "151--158",
  month    =  aug,
  year     =  2013,
  keywords = "Animacy; Case; Differential object marking; Electrophysiology;
              Event-related potentials; N400; P600; Sentence comprehension;
              Spanish",
  language = "en",
  issn     = "0093-934X, 1090-2155",
  pmid     = "23735756",
  doi      = "10.1016/j.bandl.2013.04.005"
}

@ARTICLE{Davidson2013-su,
  title   = "{Modelling accuracy as a function of response time with the
             generalized linear mixed effects model}",
  author  = "Davidson, D J and Martin, A E",
  journal = "Acta Psychol.",
  year    =  2013,
  issn    = "0001-6918"
}

@ARTICLE{Nieuwland2012-zb,
  title    = "{Brain regions that process case: evidence from Basque}",
  author   = "Nieuwland, Mante S and Martin, Andrea E and Carreiras, Manuel",
  abstract = "The aim of this event-related fMRI study was to investigate the
              cortical networks involved in case processing, an operation that
              is crucial to language comprehension yet whose neural
              underpinnings are not well-understood. What is the relationship
              of these networks to those that serve other aspects of syntactic
              and semantic processing? Participants read Basque sentences that
              contained case violations, number agreement violations or
              semantic anomalies, or that were both syntactically and
              semantically correct. Case violations elicited activity
              increases, compared to correct control sentences, in a set of
              parietal regions including the posterior cingulate, the
              precuneus, and the left and right inferior parietal lobules.
              Number agreement violations also elicited activity increases in
              left and right inferior parietal regions, and additional
              activations in the left and right middle frontal gyrus.
              Regions-of-interest analyses showed that almost all of the
              clusters that were responsive to case or number agreement
              violations did not differentiate between these two. In contrast,
              the left and right anterior inferior frontal gyrus and the
              dorsomedial prefrontal cortex were only sensitive to semantic
              violations. Our results suggest that whereas syntactic and
              semantic anomalies clearly recruit distinct neural circuits,
              case, and number violations recruit largely overlapping neural
              circuits and that the distinction between the two rests on the
              relative contributions of parietal and prefrontal regions,
              respectively. Furthermore, our results are consistent with
              recently reported contributions of bilateral parietal and
              dorsolateral brain regions to syntactic processing, pointing
              towards potential extensions of current neurocognitive theories
              of language.",
  journal  = "Hum. Brain Mapp.",
  volume   =  33,
  number   =  11,
  pages    = "2509--2520",
  series   = "Basque Human Brain Mapping",
  month    =  nov,
  year     =  2012,
  language = "en",
  issn     = "1065-9471, 1097-0193",
  pmid     = "21898678",
  doi      = "10.1002/hbm.21377",
  pmc      = "PMC6870289"
}

@ARTICLE{Martin2012-ir,
  title    = "{Event-related brain potentials index cue-based retrieval
              interference during sentence comprehension}",
  author   = "Martin, Andrea E and Nieuwland, Mante S and Carreiras, Manuel",
  abstract = "Successful language use requires access to products of past
              processing within an evolving discourse. A central issue for any
              neurocognitive theory of language then concerns the role of
              memory variables during language processing. Under a cue-based
              retrieval account of language comprehension, linguistic
              dependency resolution (e.g., retrieving antecedents) is subject
              to interference from other information in the sentence,
              especially information that occurs between the words that form
              the dependency (e.g., between the antecedent and the retrieval
              site). Retrieval interference may then shape processing
              complexity as a function of the match of the information at
              retrieval with the antecedent versus other recent or similar
              items in memory. To address these issues, we studied the online
              processing of ellipsis in Castilian Spanish, a language with
              morphological gender agreement. We recorded event-related brain
              potentials while participants read sentences containing
              noun-phrase ellipsis indicated by the determiner otro/a
              ('another'). These determiners had a grammatically correct or
              incorrect gender with respect to their antecedent nouns that
              occurred earlier in the sentence. Moreover, between each
              antecedent and determiner, another noun phrase occurred that was
              structurally unavailable as an antecedent and that matched or
              mismatched the gender of the antecedent (i.e., a local agreement
              attractor). In contrast to extant P600 results on agreement
              violation processing, and inconsistent with predictions from
              neurocognitive models of sentence processing, grammatically
              incorrect determiners evoked a sustained, broadly distributed
              negativity compared to correct ones between 400 and 1000ms after
              word onset, possibly related to sustained negativities as
              observed for referential processing difficulties. Crucially, this
              effect was modulated by the attractor: an increased negativity
              was observed for grammatically correct determiners that did not
              match the gender of the attractor, suggesting that structurally
              unavailable noun phrases were at least temporarily considered for
              grammatically correct ellipsis. These results constitute the
              first ERP evidence for cue-based retrieval interference during
              comprehension of grammatical sentences.",
  journal  = "Neuroimage",
  volume   =  59,
  number   =  2,
  pages    = "1859--1869",
  month    =  jan,
  year     =  2012,
  language = "en",
  issn     = "1053-8119, 1095-9572",
  pmid     = "21925613",
  doi      = "10.1016/j.neuroimage.2011.08.057"
}

@ARTICLE{Nieuwland2012-mb,
  title    = "{If the real world were irrelevant, so to speak: The role of
              propositional truth-value in counterfactual sentence
              comprehension}",
  author   = "Nieuwland, Mante S and Martin, Andrea E",
  abstract = "Propositional truth-value can be a defining feature of a
              sentence's relevance to the unfolding discourse, and establishing
              propositional truth-value in context can be key to successful
              interpretation. In the current study, we investigate its role in
              the comprehension of counterfactual conditionals, which describe
              imaginary consequences of hypothetical events, and are thought to
              require keeping in mind both what is true and what is false.
              Pre-stored real-world knowledge may therefore intrude upon and
              delay counterfactual comprehension, which is predicted by some
              accounts of discourse comprehension, and has been observed during
              online comprehension. The impact of propositional truth-value may
              thus be delayed in counterfactual conditionals, as also claimed
              for sentences containing other types of logical operators (e.g.,
              negation, scalar quantifiers). In an event-related potential
              (ERP) experiment, we investigated the impact of propositional
              truth-value when described consequences are both true and
              predictable given the counterfactual premise. False words
              elicited larger N400 ERPs than true words, in negated
              counterfactual sentences (e.g., ``If N.A.S.A. had not developed
              its Apollo Project, the first country to land on the moon would
              have been Russia/America'') and real-world sentences (e.g.,
              ``Because N.A.S.A. developed its Apollo Project, the first
              country to land on the moon was America/Russia'') alike. These
              indistinguishable N400 effects of propositional truth-value,
              elicited by opposite word pairs, argue against disruptions by
              real-world knowledge during counterfactual comprehension, and
              suggest that incoming words are mapped onto the counterfactual
              context without any delay. Thus, provided a sufficiently
              constraining context, propositional truth-value rapidly impacts
              ongoing semantic processing, be the proposition factual or
              counterfactual.",
  journal  = "Cognition",
  volume   =  122,
  number   =  1,
  pages    = "102--109",
  month    =  jan,
  year     =  2012,
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "21962826",
  doi      = "10.1016/j.cognition.2011.09.001"
}

@ARTICLE{Martin2011-kh,
  title    = "{Direct-access retrieval during sentence comprehension: Evidence
              from Sluicing}",
  author   = "Martin, Andrea E and McElree, Brian",
  abstract = "Language comprehension requires recovering meaning from
              linguistic form, even when the mapping between the two is
              indirect. A canonical example is ellipsis, the omission of
              information that is subsequently understood without being overtly
              pronounced. Comprehension of ellipsis requires retrieval of an
              antecedent from memory, without prior prediction, a property
              which enables the study of retrieval in situ (Martin \& McElree,
              2008, 2009). Sluicing, or inflectional phrase ellipsis, in the
              presence of a conjunction, presents a test case where a competing
              antecedent position is syntactically licensed, in contrast with
              most cases of nonadjacent dependency, including verb phrase
              ellipsis. We present speed-accuracy tradeoff and eye-movement
              data inconsistent with the hypothesis that retrieval is
              accomplished via a syntactically guided search, a particular
              variant of search not examined in past research. The observed
              timecourse profiles are consistent with the hypothesis that
              antecedents are retrieved via a cue-dependent direct-access
              mechanism susceptible to general memory variables.",
  journal  = "J. Mem. Lang.",
  volume   =  64,
  number   =  4,
  pages    = "327--343",
  month    =  may,
  year     =  2011,
  language = "en",
  issn     = "0749-596X",
  pmid     = "21580797",
  doi      = "10.1016/j.jml.2010.12.006",
  pmc      = "PMC3093705"
}

@ARTICLE{Martin2009-ce,
  title    = "{Memory operations that support language comprehension: evidence
              from verb-phrase ellipsis}",
  author   = "Martin, Andrea E and McElree, Brian",
  abstract = "Comprehension of verb-phrase ellipsis (VPE) requires reevaluation
              of recently processed constituents, which often necessitates
              retrieval of information about the elided constituent from
              memory. A. E. Martin and B. McElree (2008) argued that
              representations formed during comprehension are content
              addressable and that VPE antecedents are retrieved from memory
              via a cue-dependent direct-access pointer rather than via a
              search process. This hypothesis was further tested by
              manipulating the location of interfering material-either before
              the onset of the antecedent (proactive interference; PI) or
              intervening between antecedent and ellipsis site (retroactive
              interference; RI). The speed-accuracy tradeoff procedure was used
              to measure the time course of VPE processing. The location of the
              interfering material affected VPE comprehension accuracy: RI
              conditions engendered lower accuracy than PI conditions.
              Crucially, location did not affect the speed of processing VPE,
              which is inconsistent with both forward and backward search
              mechanisms. The observed time-course profiles are consistent with
              the hypothesis that VPE antecedents are retrieved via a
              cue-dependent direct-access operation.",
  journal  = "J. Exp. Psychol. Learn. Mem. Cogn.",
  volume   =  35,
  number   =  5,
  pages    = "1231--1239",
  month    =  sep,
  year     =  2009,
  language = "en",
  issn     = "0278-7393",
  pmid     = "19686017",
  doi      = "10.1037/a0016271",
  pmc      = "PMC2849635"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Pylkkanen2009-qw,
  title    = "{The Anterior Midline Field: coercion or decision making?}",
  author   = "Pylkk{\"a}nen, Liina and Martin, Andrea E and McElree, Brian and
              Smart, Andrew",
  abstract = "To study the neural bases of semantic composition in language
              processing without confounds from syntactic composition, recent
              magnetoencephalography (MEG) studies have investigated the
              processing of constructions that exhibit some type of
              syntax-semantics mismatch. The most studied case of such a
              mismatch is complement coercion; expressions such as the author
              began the book, where an entity-denoting noun phrase is coerced
              into an eventive meaning in order to match the semantic
              properties of the event-selecting verb (e.g., 'the author began
              reading/writing the book'). These expressions have been found to
              elicit increased activity in the Anterior Midline Field (AMF), an
              MEG component elicited at frontomedial sensors at approximately
              400 ms after the onset of the coercing noun [Pylkk{\"a}nen, L.,
              \& McElree, B. (2007). An MEG study of silent meaning. Journal of
              Cognitive Neuroscience, 19, 11]. Thus, the AMF constitutes a
              potential neural correlate of coercion. However, the AMF was
              generated in ventromedial prefrontal regions, which are heavily
              associated with decision-making. This raises the possibility
              that, instead of semantic processing, the AMF effect may have
              been related to the experimental task, which was a sensicality
              judgment. We tested this hypothesis by assessing the effect of
              coercion when subjects were simply reading for comprehension,
              without a decision-task. Additionally, we investigated coercion
              in an adjectival rather than a verbal environment to further
              generalize the findings. Our results show that an AMF effect of
              coercion is elicited without a decision-task and that the effect
              also extends to this novel syntactic environment. We conclude
              that in addition to its role in non-linguistic higher cognition,
              ventromedial prefrontal regions contribute to the resolution of
              syntax-semantics mismatches in language processing.",
  journal  = "Brain Lang.",
  volume   =  108,
  number   =  3,
  pages    = "184--190",
  month    =  mar,
  year     =  2009,
  file     = "All Papers/P/Pylkkänen et al. 2009 -brain lang - The Anterior Midline Field - coercion or decision making.pdf",
  language = "en",
  issn     = "0093-934X, 1090-2155",
  pmid     = "18678402",
  doi      = "10.1016/j.bandl.2008.06.006"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Martin2008-gm,
  title     = "{A content-addressable pointer mechanism underlies comprehension
               of verb-phrase ellipsis☆}",
  author    = "Martin, Andrea E and McElree, Brian",
  abstract  = "Interpreting a verb-phrase ellipsis (VP ellipsis) requires
               accessing an antecedent in memory, and then integrating a
               representation of this antecedent into the local context. We
               investigated the online interpretation of VP ellipsis in an
               eye-tracking experiment and four speed--accuracy tradeoff
               experiments. To investigate whether the antecedent for a VP
               ellipsis is accessed with a search or direct-access retrieval
               process, Experiments 1 and 2 measured the effect of the distance
               between an ellipsis and its antecedent on the speed and accuracy
               of comprehension. Accuracy was lower with longer distances,
               indicating that interpolated material reduced the quality of
               retrieved information about the antecedent. However, contra a
               search process, distance did not affect the speed of
               interpreting ellipsis. This pattern suggests that antecedent
               representations are content-addressable and retrieved with a
               direct-access process. To determine whether interpreting
               ellipsis involves copying antecedent information into the
               ellipsis site, Experiments 3--5 manipulated the length and
               complexity of the antecedent. Some types of antecedent
               complexity lowered accuracy, notably, the number of discourse
               entities in the antecedent. However, neither antecedent length
               nor complexity affected the speed of interpreting the ellipsis.
               This pattern is inconsistent with a copy operation, and it
               suggests that ellipsis interpretation may involve a pointer to
               extant structures in memory.",
  journal   = "J. Mem. Lang.",
  publisher = "Elsevier BV",
  volume    =  58,
  number    =  3,
  pages     = "879--906",
  month     =  apr,
  year      =  2008,
  language  = "en",
  issn      = "0749-596X, 1096-0821",
  doi       = "10.1016/j.jml.2007.06.010"
}

@ARTICLE{Ashby2008-lf,
  title    = "{Prosodic phonological representations early in visual word
              recognition}",
  author   = "Ashby, Jane and Martin, Andrea E",
  abstract = "Two experiments examined the nature of the phonological
              representations used during visual word recognition. We tested
              whether a minimality constraint (R. Frost, 1998) limits the
              complexity of early representations to a simple string of
              phonemes. Alternatively, readers might activate elaborated
              representations that include prosodic syllable information before
              lexical access. In a modified lexical decision task (Experiment
              1), words were preceded by parafoveal previews that were
              congruent with a target's initial syllable as well as previews
              that contained 1 letter more or less than the initial syllable.
              Lexical decision times were faster in the syllable congruent
              conditions than in the incongruent conditions. In Experiment 2,
              we recorded brain electrical potentials (electroencephalograms)
              during single word reading in a masked priming paradigm. The
              event-related potential waveform elicited in the syllable
              congruent condition was more positive 250-350 ms posttarget
              compared with the waveform elicited in the syllable incongruent
              condition. In combination, these experiments demonstrate that
              readers process prosodic syllable information early in visual
              word recognition in English. They offer further evidence that
              skilled readers routinely activate elaborated, speechlike
              phonological representations during silent reading.",
  journal  = "J. Exp. Psychol. Hum. Percept. Perform.",
  volume   =  34,
  number   =  1,
  pages    = "224--236",
  month    =  feb,
  year     =  2008,
  file     = "All Papers/A/Ashby and Martin 2008 -j exp psychol hum percept perform - Prosodic phonological representations early in visual word recognition.pdf",
  language = "en",
  issn     = "0096-1523",
  pmid     = "18248150",
  doi      = "10.1037/0096-1523.34.1.224"
}

@UNPUBLISHED{Foraker_undated-ka,
  title   = "{Speed-accuracy tradeoff modeling and its interface with
             experimental syntax}",
  author  = "Foraker, S and Cunnings, I and Martin, A E",
  journal = "psyarxiv",
  file    = "All Papers/F/Foraker et al. -psyarxiv - Speed-accuracy tradeoff modeling and its interface with experimental syntax.pdf"
}

@UNPUBLISHED{Doumas_undated-cz,
  title   = "{Human-like generalization in a machine through predicate learning}",
  author  = "Doumas, L A A and Puebla, G and Martin, A E",
  journal = "arxiv",
  file    = "All Papers/D/Doumas et al. -arxiv - Human-like generalization in a machine through predicate learning.pdf"
}

@UNPUBLISHED{Doumas_undated-te,
  title   = "{How we learn things we didn't know already: A theory of learning
             structured representations from experience}",
  author  = "Doumas, L A A and Puebla, G and Martin, A E",
  journal = "bioRxiv",
  file    = "All Papers/D/Doumas et al. -biorxiv - How we learn things we didn't know already - A theory of learning structured representations from experience.pdf"
}

@UNPUBLISHED{Kaushik_undated-lz,
  title   = "{Modelling compositionality and structure dependence in natural
             language}",
  author  = "Kaushik, K R and Martin, A E",
  journal = "arxiv",
  file    = "All Papers/K/Kaushik and Martin -arxiv - Modelling compositionality and structure dependence in natural language.pdf"
}
